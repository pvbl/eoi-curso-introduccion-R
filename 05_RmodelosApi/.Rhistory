sum(df$tenure==0)
#sum(df$tenure==0)
```
# evalúa cual es el valor más frecuente de la variable tenure para el subset anterior. Luego mira dentro de todo el dataframe, cuantas veces aparece repetido ese valor más frecuente. ¿Qué crees que puede decirnos esto?
# A qué crees que se debe esto?
sort(table(df[is.na(df$TotalCharges),]$tenure),decreasing=TRUE)
sum(df$tenure==0)
# imputa el valor de los nans a la columna TotalCharges
df[is.na(df$TotalCharges),]
# imputa el valor de los nans a la columna TotalCharges
df[is.na(df$TotalCharges),"TotalCharger"]#<-0
# imputa el valor de los nans a la columna TotalCharges
df[is.na(df$TotalCharges),"TotalCharges"]#<-0
# imputa el valor de los nans a la columna TotalCharges
df[is.na(df$TotalCharges),"TotalCharges"]<-0
# chequea que no hay missing values ahora
sum(is.na(df))
df$Dependents
df$age
table(df$age)
df$age<-NULL
mutate_if(df, is.character, as.factor)
# transforma las variables tipo str a factor. Usa para ello la función
## mutate_if(dataframe,condicion,funcion de conversion)
str(mutate_if(df, is.character, as.factor))
# transforma las variables tipo str a factor. Usa para ello la función
## mutate_if(dataframe,condicion,funcion de conversion)
df<- mutate_if(df, is.character, as.factor)
create_report(df,
y = "Churn", #choose a response variable
config = configurations,
report_title= "mtcars Dataset Report")
configurations <-configure_report(
add_plot_histogram = TRUE, #excluding some plots
add_plot_str = FALSE,
add_plot_qq = FALSE,
add_plot_correlation = TRUE,
add_plot_prcomp= FALSE,
add_plot_boxplot = FALSE,
global_ggtheme = theme_bw() #setting theme
)
create_report(df,
y = "Churn", #choose a response variable
config = configurations,
report_title= "churn Dataset Report")
plot_correlation(
df,
type = c("all", "discrete", "continuous"),
maxcat = 20L,
cor_args = list(),
geom_text_args = list(),
title = NULL,
ggtheme = theme_gray(),
theme_config = list(legend.position = "bottom", axis.text.x = element_text(angle =
90))
)
plot_correlation(
df,
type = c("continuous"),
maxcat = 20L,
cor_args = list(),
geom_text_args = list(),
title = NULL,
ggtheme = theme_gray(),
theme_config = list(legend.position = "bottom", axis.text.x = element_text(angle =
90))
)
# haz una división train test split usando initial_split con una prop de 3/4
train_test_split <- initial_split(df, prop = 3/4, strata = "Churn")
library('rsample')
# haz una división train test split usando initial_split con una prop de 3/4 de la librería rsample
train_test_split <- initial_split(df, prop = 3/4, strata = "Churn")
train <- training(train_test_split)
test <- testing(train_test_split)
# haz un arbol de decision
# evalua sus métricas
# plotea el arbol de decision
tree <- rpart(Loan_Status ~ ., data = train, method = 'class')
library(rpart)
library(rpart.plot)
# haz un arbol de decision con rpart
# evalua sus métricas
# plotea el arbol de decision
tree <- rpart(Churn ~ ., data = train, method = 'class')
rpart.plot(tree)
# haz una división train test split usando initial_split con una prop de 3/4 de la librería rsample
# elimina la varible del df CustomerID (si no lo has hecho antes)
df$customerID<-NULL
library(rpart)
library(rpart.plot)
# haz un arbol de decision con rpart
# evalua sus métricas
# plotea el arbol de decision
tree <- rpart(Churn ~ ., data = train, method = 'class')
# haz una división train test split usando initial_split con una prop de 3/4 de la librería rsample
# elimina la varible del df CustomerID (si no lo has hecho antes)
df$customerID<-NULL
train_test_split <- initial_split(df, prop = 3/4, strata = "Churn")
train <- training(train_test_split)
test <- testing(train_test_split)
library(rpart)
library(rpart.plot)
# haz un arbol de decision con rpart
# evalua sus métricas
# plotea el arbol de decision
tree <- rpart(Churn ~ ., data = train, method = 'class')
rpart.plot(tree)
varImp(tree,scale = FALSE)
caret::confusionMatrix(pred, test$Loan_Status)
pred <- predict(tree,newdata  = test)
caret::confusionMatrix(pred, test$Churn)
tree
pred <- predict(tree, newdata  = test)
caret::confusionMatrix(pred, test$Churn)
#caret::confusionMatrix(pred, test$)
pred
pred <- predict(tree, newdata  = test,type = 'class')
#caret::confusionMatrix(pred, test$)
pred
pred <- predict(tree, newdata  = test,type = 'class')
caret::confusionMatrix(pred, test$Churn)
# haz un random forest con caret, usa el siguiente trainControl para ello,
# y la métrica ROC
ctrl <- trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary)
rf <- train(form = Churn ~ .,
data = train,
trControl = ctrl,
metric = "ROC",
method = "rf")
rf
# evalúa el performance del modelo
pred <- predict(rf, newdata  = test,type = 'class')
# evalúa el performance del modelo
pred <- predict(rf, newdata  = test)
caret::confusionMatrix(pred, test$Churn)
# Adjusting the ui
ui <- fluidPage(
headerPanel('Iris k-means clustering'),
sidebarPanel(
selectInput('xcol', 'X Variable', names(iris)),
selectInput('ycol', 'Y Variable', names(iris),
selected = names(iris)[[2]]),
numericInput('clusters', 'Cluster count', 3,
min = 1, max = 9)
),
mainPanel(
plotOutput('plot1')
)
)
#install.packages(c("shiny","plotly","psych"))
library(shiny)
library(plotly)
# Adjusting the ui
ui <- fluidPage(
headerPanel('Iris k-means clustering'),
sidebarPanel(
selectInput('xcol', 'X Variable', names(iris)),
selectInput('ycol', 'Y Variable', names(iris),
selected = names(iris)[[2]]),
numericInput('clusters', 'Cluster count', 3,
min = 1, max = 9)
),
mainPanel(
plotOutput('plot1')
)
)
# Adjusting Server settings (data input and output)
server <- function(input, output) {
selectedData <- reactive({
iris[, c(input$xcol, input$ycol)]
})
clusters <- reactive({
kmeans(selectedData(), input$clusters)
})
output$plot1 <- renderPlot({
par(mar = c(5.1, 4.1, 0, 1))
plot(selectedData(),
col = clusters()$cluster,
pch = 20, cex = 3)
points(clusters()$centers, pch = 4, cex = 4, lwd = 4)
})
}
shinyApp(ui = ui, server = server)   # Launching the Shiny App
knitr::opts_chunk$set(echo = TRUE)
ggplot(df, aes(tenure)) + geom_hist(aes(col=tenure), size=4)
library(ggplot2)
# haz un histograma con ggplot2 de tenure
hist(df$tenure,breaks=50)
ggplot(df, aes(tenure)) + geom_hist(aes(col=tenure), size=4)
ggplot(df, aes(tenure)) + geom_histogram(aes(col=tenure), size=4)
ggplot(df, aes(tenure)) + geom_histogram(aes(col=Churn))
ggplot(df, aes(tenure,col=Churn)) + geom_histogram()
rapply(df,count_ceros)
colSums(df)
#colSums(df)
```
# analisis del numero de ceros total
## saca el número de ceros que tiene cada columna numérica
rapply(df,is.numeric)
# analisis del numero de ceros total
## saca el número de ceros que tiene cada columna numérica
filter(df,is.numeric)
rapply
# analisis del numero de ceros total
## saca el número de ceros que tiene cada columna numérica
df[rapply(df,is.numeric),]
library(ggfortify)
install.packages(c("tseries","forecast"))
library(ggfortify)
library(tseries)
library(forecast)
head(AirPassengers)
class(AirPassengers)
plot(AirPassengers)
start(AirPassengers)
end(AirPassengers)
frequency(AirPassengers)
deltat(AirPassengers)
head(time(AirPassengers))
# Check the cycle of the time series
cycle(AirPassengers)
summary(AirPassengers)
data(Boston, package="MASS")
library(randomForest)
# train a model for median house price as a function of the other variables
bos_rf <- randomForest(medv ~ ., data=Boston, ntree=100)
# save the model
saveRDS(bos_rf, "bos_rf.rds")
bos_rf <- readRDS("~/freelance/docencia/EOI/clases/introduccion_a_R/01_basicos-R/cursoRbasico/05_RmodelosApi/bos_rf.rds")
# save as bos_rf_score.R
#* @post /bostrf
bos_rf <- readRDS("bos_rf.rds")
library(randomForest)
#* @param df data frame of variables
#* @post /score
function(req, df)
{
df <- as.data.frame(df)
predict(bos_rf, df)
}
r = plumb(file = "bos_rf_score.R", dir ='R/model_deploy')
r = plumb(file = "bos_rf_score.R", dir ='R/model_deploy')
install.packages("plumber")
library("plumber")
r = plumb(file = "bos_rf_score.R", dir ='R/model_deploy')
r = plumb(file = "bos_rf_score.R", dir ='model_deploy')
r = plumb(file = "bos_rf_score.R", dir ='.')
r = plumb(file = "bos_rf_score.R", dir ='.')
r = plumb(file = "bos_rf_score.R", dir ='R/model_deploy')
r = plumb(file = "bos_rf_score.R", dir ='.')
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R", dir ='.')
r = plumb(file = "bos_rf_score.R", dir ='.')
# save as bos_rf_score.R
#* @post /bostrf
bos_rf <- readRDS("bos_rf.rds")
library(randomForest)
#* @param df data frame of variables
#* @post /score
function(req, df)
{
df <- as.data.frame(df)
predict(bos_rf, df)
}
r = plumb(file = "bos_rf_score.R", dir ='.')
r = plumb(file = "bos_rf_score.R", dir ='.')
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R", dir ='.')
r = plumb(file = "bos_rf_score.R", dir ='.')
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R", dir ='.')
r = plumb(file = "bos_rf_score.R", dir ='.')
r$run(port = 1030, host = "0.0.0.0")
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R", dir ='.')
r$run(port = 1030, host = "0.0.0.0")
#install.packages("dbscan")
library(ggplot2)
library(dbscan)
library(tidyverse)
df<-iris
head(df)
ggplot(df, aes(Petal.Length, Petal.Width)) + geom_point(aes(col=Species), size=4)
normalize <- function(x){
return ((x-min(x))/(max(x)-min(x)))
}
df[,c(1:4)]<-lapply(df[,c(1:4)],normalize)
colMeans(df[,c(1:4)])
prop.table(table(df$Species))
table(df$Species)
prop.table(table(df$Species))
set.seed(101)
cluster_mod <- kmeans(df[,1:4], center=3, nstart=20)
cluster_mod
table(cluster_mod$cluster, df$Species)
#install.packages("cluster")
library(cluster)
clusplot(iris, cluster_mod$cluster, color=T, shade=T, labels=0, lines=0)
tot.withinss <- vector(mode="character", length=10)
for (i in 1:10){
clusterM <- kmeans(df[,1:4], center=i, nstart=20)
tot.withinss[i] <- clusterM$tot.withinss
}
plot(1:10, tot.withinss, type="b", pch=19)
hc = hclust(dist(df[,c(1:4)]), method = "ward.D")
hc
plot(hc, hang = -5)
dbscanM=dbscan(df[,c(1:4)], eps=0.2, minPts = 3)
df$clusterDB=dbscanM$cluster
ggplot(df,aes(Petal.Length, Petal.Width,color=as.factor(clusterDB)))+geom_point()
pcaM <- prcomp(df[,c(1:4)], center = TRUE, scale = TRUE)
print(pcaM)
l
pcaM <- prcomp(df[,c(1:4)], center = TRUE, scale = TRUE)
print(pcaM)
plot(pcaM, type='l')
summary(pcaM)
r = plumb(file = "bos_rf_score.R")
r$run(port = 1030, host = "0.0.0.0")
Boston
Boston[0]
Boston[,1]
Boston[1,]
library(jsonlite)
toJSON(Boston[1,])
r = plumb(file = "bos_rf_score.R")
r$run(port = 1030, host = "0.0.0.0")
# save as bos_rf_score.R
#* @post /bostrf
bos_rf <- readRDS("bos_rf.rds")
library(randomForest)
#* @param df data frame of variables
#* @post /score
function(df)
{
df <- as.data.frame(df)
predict(bos_rf, df)
}
r = plumb(file = "bos_rf_score.R")
# save as bos_rf_score.R
bos_rf <- readRDS("bos_rf.rds")
library(randomForest)
#* @param df data frame of variables
#* @post /score
function(req, df)
{
df <- as.data.frame(df)
predict(bos_rf, df)
}
bos_rf <- readRDS("bos_rf.rds")
r = plumb(file = "bos_rf_score.R")
toJSON(Boston[1,])
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R")
r$run(port = 1030, host = "0.0.0.0")
r$run(port = 1030, host = "0.0.0.0")
#* @param df data frame of variables
#* @post /score
function(df)
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R")
r$run(port = 1030, host = "0.0.0.0")
data(Boston, package="MASS")
library(randomForest)
# train a model for median house price as a function of the other variables
bos_rf <- randomForest(medv ~ zn + crim + indus, data=Boston, ntree=100)
# save the model
saveRDS(bos_rf, "bos_rf.rds")
toJSON(Boston[1,1:3])
# save as bos_rf_score.R
bos_rf <- readRDS("bos_rf.rds")
library(randomForest)
#* @param df data frame of variables
#* @post /score
function(crim,zn,indus)
{
df <- as.data.frame(
crim = crim,
zn = zn,
indus = indus
)
predict(bos_rf, df)
}
r = plumb(file = "bos_rf_score.R")
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R")
r$run(port = 1030, host = "0.0.0.0")
r$run(port = 1030, host = "0.0.0.0")
#install.packages('rattle')
data(wine, package='rattle')
head(wine)
str(wine) %>% drop_na()
wine_df$clusterDB
library(dbscan)
dbscanM=dbscan(wine_df, eps=0.3, minPts = 3)
r$run(port = 1030, host = "0.0.0.0")
r = plumb(file = "bos_rf_score.R")
r$run(port = 1030, host = "0.0.0.0")
# analisis del numero de ceros total
## saca el número de ceros que tiene cada columna numérica
colSums(df==0)
# analisis del numero de ceros total
## saca el número de ceros que tiene cada columna numérica
df==0
)
library(caret)
head(df)
# mira la tipología de cada una de las variables (str,int,float),...
# chequea tenga coherencia (que esté cargando correctamente los numéricos, str,...). En caso de que no sea así, identifica y corrige el problema.
str(df)
ncol(df)
df <- read.csv2("https://raw.githubusercontent.com/pvbl/churn-modeling-telco-data/main/telco_dataset.csv", sep=",",dec=".")
head(df)
# plotea los missing values con Data Explorer+
plot_missing(df)
# analisis del numero de ceros total
## saca el número de ceros que tiene cada columna numérica
colSums(df==0)
## lee los datos
url <-"https://raw.githubusercontent.com/pvbl/churn-modeling-telco-data/main/telco_dataset.csv"
# mira la tipología de cada una de las variables (str,int,float),...
# chequea tenga coherencia (que esté cargando correctamente los numéricos, str,...). En caso de que no sea así, identifica y corrige el problema.
str(df)
plot_str(df)
# mira la tipología de cada una de las variables (str,int,float),...
# chequea tenga coherencia (que esté cargando correctamente los numéricos, str,...). En caso de que no sea así, identifica y corrige el problema.
## muestra el número de filas y columnas
## muestra un sumary de los datos
```
##¿Existe alguna(s) variable(s) que sea constante (tenga todos los valores iguales)? Usa para ello la función n_distinct de tidyverse
## Si es así eliminala(s)
# Evalúa el número de duplicados. En caso de que haya, ¿cuantos hay? Eliminalos
# idenfica si después de eliminar los duplicados, existe algún customerID duplicado.
# Haz un descriptivo con plot_intro de DataExplorer
# plotea los missing values con Data Explorer+
# haz un summary del subset del dataframe que contenga los nans (filtra el dataframe con todos los nans y haz un sumary)
# evalúa cual es el valor más frecuente de la variable tenure para el subset anterior. Luego mira dentro de todo el dataframe, cuantas veces aparece repetido ese valor más frecuente. ¿Qué crees que puede decirnos esto?
# A qué crees que se debe esto? ¿Qué valor crees que hay que imputar en los NaNs¿
# imputa el valor de los nans a la columna TotalCharges
# chequea que no hay missing values ahora
# analisis del numero de ceros total
## saca el número de ceros que tiene cada columna
## ¿ Qué columna tiene más ceros y a qué se debe?
# transforma las variables tipo str a factor. Usa para ello la función
## mutate_if(dataframe,condicion,funcion de conversion)
# haz un histograma con ggplot2 de tenure que tenga coloreado los bines según el churn
# haz un report de dataexplorer en el que estén los histogramas
## ¿Qué tipo de distribución ves en MonthlyCharges, qué particularidad tiene?
##
# utiliza la función de plot_correlation de dataexplorer, pon que el tipo de variables a evaluar son sólo las tipo "continuous"
## ¿ves algunas variables que tengan una correlación alta y que puedan significar lo mismo (>0.90)?
## elimina aquella que creas más conveniente
# haz una división train test split usando initial_split con una prop de 3/4 de la librería rsample
# elimina la varible del df CustomerID (si no lo has hecho antes)
# haz un arbol de decision con rpart
# evalua sus métricas con ConfusionMatrix
# plotea el arbol de decision y su feature importance
# haz un random forest con caret, usa el siguiente trainControl para ello,
# y la métrica ROC
ctrl <- trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary)
rf <- train(form = Churn ~ .,
data = train,
trControl = ctrl,
metric = "ROC",
method = "rf")
rf
# evalúa el performance del modelo
pred <- predict(rf, newdata  = test)
caret::confusionMatrix(pred, test$Churn)
caTools::colAUC(probs,TEST$diabetes,plotROC = TRUE)
caTools::colAUC(probs,test$Churn,plotROC = TRUE)
probs <- predict(rf,test,type="prob")[,2]
caTools::colAUC(probs,test$Churn,plotROC = TRUE)
# plotea la curva ROC usando la librería caTools
rf <- train(form = Churn ~ .,
data = train,
trControl = ctrl,
metric = "ROC",
method = "xgboost")
xgboost <- train(form = Churn ~ .,
data = train,
trControl = ctrl,
metric = "ROC",
method = "xgboost")
xgboost <- train(form = Churn ~ .,
data = train,
trControl = ctrl,
metric = "ROC",
method = "xgbTree")
xgboost
# evalúa el performance del modelo
pred <- predict(xgboost, newdata  = test)
caret::confusionMatrix(pred, test$Churn)
knitr::opts_chunk$set(echo = TRUE)
probs <- predict(xgboost,test,type="prob")[,2]
caTools::colAUC(probs,test$Churn,plotROC = TRUE)
varImp(xgboost)
# haz un random forest con caret, usa el siguiente trainControl para ello, la métrica de optimización es la ROC (metric=ROC)
# evalúa el performance del modelo como con el árbol de decisión
# plotea la importancia de las variables
# plotea la curva ROC usando la librería caTools
# ¿piensas que son los resultados congruentes a partir del feature importance?
ctrl <- trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary)
